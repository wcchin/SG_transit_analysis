{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../data\"\n",
    "bus_dir = os.path.join(data_dir, \"OD_bus\")\n",
    "train_dir = os.path.join(data_dir, \"OD_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizing(df, col=\"flow\"):\n",
    "    vals = df[col].tolist()\n",
    "    ma = max(vals)\n",
    "    mi = min(vals)\n",
    "    ra = ma - mi\n",
    "    vals2 = [ (v-mi)/ra if ra>0 else 0 for v in vals ]\n",
    "    df[col] = vals2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 9249 8473 15966\n",
      "6 17733 11042 25212\n",
      "7 19521 11733 27085\n",
      "8 19691 11837 27241\n",
      "9 19591 11746 27073\n",
      "10 19761 11790 27174\n",
      "11 20017 11852 27424\n",
      "12 20301 11980 27763\n",
      "13 20442 11957 27868\n",
      "14 20508 11945 27893\n",
      "15 20557 11995 27974\n",
      "16 20679 12129 28192\n",
      "17 20925 12336 28572\n",
      "18 20916 12267 28531\n",
      "19 20040 11949 27609\n",
      "20 19358 11655 26805\n",
      "21 19118 11430 26397\n",
      "22 18558 11032 25634\n",
      "23 17013 9237 22905\n"
     ]
    }
   ],
   "source": [
    "months = [\"202001\"] #\"201911\", \"201912\"\n",
    "for m in months:\n",
    "    for hr in range(5,24):\n",
    "        #print(hr)\n",
    "        f = \"OD_{}_weekday_{}.csv.xz\".format(m, str(hr).zfill(2))\n",
    "        bus_fp = os.path.join(bus_dir, f)\n",
    "        #print(bus_fp)\n",
    "        train_fp = os.path.join(train_dir, f)\n",
    "        df_bus = pd.read_csv(bus_fp, index_col=0)\n",
    "        df_train = pd.read_csv(train_fp, index_col=0)\n",
    "        #print(df_bus.head())\n",
    "        #print(df_train.head())\n",
    "        df_bus = df_bus[[\"origin\", \"destination\", \"flow\"]]\n",
    "        #df_bus = normalizing(df_bus, col=\"flow\")\n",
    "        df_train = df_train[[\"origin\", \"destination\", \"flow\"]]\n",
    "        #df_train = normalizing(df_train, col=\"flow\")\n",
    "        df_merge = pd.merge(df_bus, df_train, left_on=[\"origin\", \"destination\"], right_on=[\"origin\", \"destination\"], \n",
    "                            how=\"outer\", suffixes=('_bus', '_train'))#, validate=\"one_to_one\")\n",
    "        df_merge = df_merge.fillna(value={\"flow_bus\":0, \"flow_train\":0})\n",
    "        df_merge[\"hour\"] = hr\n",
    "        df_merge[\"total_flow\"] = (df_merge[\"flow_bus\"] + df_merge[\"flow_train\"])\n",
    "        #print(df_merge.head())\n",
    "        df_merge.to_csv(os.path.join(data_dir, \"OD_PT\", f), compression=\"xz\")\n",
    "        print(hr, len(df_bus), len(df_train), len(df_merge))\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 7107 6444 12410\n",
      "6 15217 10032 22307\n",
      "7 16983 10760 24328\n",
      "8 17695 10990 24981\n",
      "9 17946 10967 25127\n",
      "10 18374 11097 25518\n",
      "11 18773 11293 26014\n",
      "12 19049 11464 26337\n",
      "13 19135 11413 26358\n",
      "14 19025 11358 26214\n",
      "15 19094 11395 26339\n",
      "16 19188 11521 26526\n",
      "17 19350 11578 26716\n",
      "18 18955 11541 26354\n",
      "19 18620 11283 25887\n",
      "20 18060 11007 25251\n",
      "21 17691 10748 24727\n",
      "22 17052 10186 23742\n",
      "23 15451 8133 20719\n"
     ]
    }
   ],
   "source": [
    "months = [\"202001\"] #\"201911\", \"201912\"\n",
    "for m in months:\n",
    "    for hr in range(5,24):\n",
    "        #print(hr)\n",
    "        f = \"OD_{}_weekend_{}.csv.xz\".format(m, str(hr).zfill(2))\n",
    "        bus_fp = os.path.join(bus_dir, f)\n",
    "        train_fp = os.path.join(train_dir, f)\n",
    "        df_bus = pd.read_csv(bus_fp, index_col=0)\n",
    "        df_train = pd.read_csv(train_fp, index_col=0)\n",
    "        #print(df_bus.head())\n",
    "        #print(df_train.head())\n",
    "        df_bus = df_bus[[\"origin\", \"destination\", \"flow\"]]\n",
    "        #df_bus = normalizing(df_bus, col=\"flow\")\n",
    "        df_train = df_train[[\"origin\", \"destination\", \"flow\"]]\n",
    "        #df_train = normalizing(df_train, col=\"flow\")\n",
    "        df_merge = pd.merge(df_bus, df_train, left_on=[\"origin\", \"destination\"], right_on=[\"origin\", \"destination\"], \n",
    "                            how=\"outer\", suffixes=('_bus', '_train'))#, validate=\"one_to_one\")\n",
    "        df_merge = df_merge.fillna(value={\"flow_bus\":0, \"flow_train\":0})\n",
    "        df_merge[\"hour\"] = hr\n",
    "        df_merge[\"total_flow\"] = (df_merge[\"flow_bus\"] + df_merge[\"flow_train\"])\n",
    "        #print(df_merge.head())\n",
    "        df_merge.to_csv(os.path.join(data_dir, \"OD_PT\", f), compression=\"xz\")\n",
    "        print(hr, len(df_bus), len(df_train), len(df_merge))\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
